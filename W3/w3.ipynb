{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/content/drive/My Drive/COS30082/W3/Titanic-Dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop irrelevant columns (would likely not affect the result)\n",
    "df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "\n",
    "# Encode categorical variables (Sex, Embarked (txt->int))\n",
    "df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n",
    "df['Embarked'] = df['Embarked'].map({'C': 1, 'Q': 2, 'S': 3})\n",
    "\n",
    "# Handle missing values (fill Age & Fare with median, Embarked with mode)\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "\n",
    "# Define features (independent variables) and target (dependent variable)\n",
    "X = df.drop(columns=['Survived'])  # Target feature droped out from training\n",
    "y = df['Survived']                 # Target variable\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X[['Age', 'Fare', 'Embarked', 'Sex']] = scaler.fit_transform(X[['Age', 'Fare', 'Embarked', 'Sex']])\n",
    "\n",
    "# 1. Train-Test Split & Logistic Regression Model (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=200)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# 2. Predictions & Model Evaluation\n",
    "y_pred = log_reg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# 3. Display Theta Parameter Values (Coefficients)\n",
    "print(\"\\nTheta (Coefficients) for Features:\")\n",
    "theta_values = pd.DataFrame(log_reg.coef_.flatten(), index=X.columns, columns=['Coefficient'])\n",
    "print(theta_values)\n",
    "\n",
    "# 4. Making Predictions for 3 Sample Passengers (random)\n",
    "sample_data = pd.DataFrame({\n",
    "    'Pclass': [1, 3, 2],   \n",
    "    'Sex': [0, 1, 0],      \n",
    "    'Age': [25, 40, 3],    \n",
    "    'SibSp': [0, 1, 0],    \n",
    "    'Parch': [0, 2, 1],    \n",
    "    'Fare': [71, 7.5, 12], \n",
    "    'Embarked': [1, 3, 2]  \n",
    "})\n",
    "\n",
    "# Apply same normalization\n",
    "sample_data[['Age', 'Fare', 'Embarked', 'Sex']] = scaler.transform(sample_data[['Age', 'Fare', 'Embarked', 'Sex']])\n",
    "\n",
    "# Make predictions\n",
    "sample_predictions = log_reg.predict(sample_data)\n",
    "\n",
    "# Convert predictions to text format (1/0)\n",
    "sample_results = [\"Survived\" if pred == 1 else \"Not Survived\" for pred in sample_predictions]\n",
    "sample_data['Prediction'] = sample_results # Embed prediction to sample data -> result\n",
    "\n",
    "print(\"\\nPredictions for 3 Sample Passengers:\")\n",
    "print(sample_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Prediction']]) # List other features pred data (post norm)\n",
    "\n",
    "# 5. Alter Train-Test Split & Max Iterations and Observe Changes\n",
    "split_variants = [0.1, 0.3, 0.5]\n",
    "iteration_variants = [100, 500, 1000]\n",
    "\n",
    "print(\"\\nðŸ›  Effect of Different Splits & Iterations on Model Performance:\")\n",
    "for split in split_variants:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=42)\n",
    "    \n",
    "    for max_iter in iteration_variants:\n",
    "        log_reg = LogisticRegression(max_iter=max_iter)\n",
    "        log_reg.fit(X_train, y_train)\n",
    "        y_pred = log_reg.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Test Size: {split}, Max Iter: {max_iter} => Accuracy: {acc:.4f}, Recall: {rec:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7 (main, Oct 10 2024, 10:50:01) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1062708a37074d70712b695aadee582e0b0b9f95f45576b5521424137d05fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
